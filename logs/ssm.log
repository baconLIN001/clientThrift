[INFO] [2017-03-17 18:31:12][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-17 18:40:12][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-17 18:40:12][com.bacon.client.thrift.RequestReceiver]
Running Server in : 9922
[INFO] [2017-03-17 18:53:02][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-17 18:53:02][com.bacon.client.thrift.RequestReceiver]
Running Server in : 9922
[INFO] [2017-03-17 18:53:07][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-17 18:53:07][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-17 18:53:07][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-17 18:53:07][com.bacon.client.App]Running
[INFO] [2017-03-17 20:38:57][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-17 20:38:57][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-17 20:38:57][com.bacon.client.thrift.RunningServer]Server Start Fail!
[INFO] [2017-03-17 20:39:34][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-17 20:39:34][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-17 20:39:42][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-17 20:39:42][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-17 20:39:42][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-17 20:39:42][com.bacon.client.App]Running
[INFO] [2017-03-17 20:50:30][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-17 20:50:30][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-17 20:50:30][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-17 20:50:39][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-17 20:50:39][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-17 20:50:39][com.bacon.client.App]Running
[INFO] [2017-03-20 14:38:23][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-20 14:41:42][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-20 14:42:16][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-20 16:06:26][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-21 10:43:45][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-21 10:43:45][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-21 10:43:45][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-21 10:44:01][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-21 10:44:02][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-21 10:44:02][com.bacon.client.App]Running
[INFO] [2017-03-22 20:44:14][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-22 20:44:14][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-22 20:44:14][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-22 20:44:20][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-22 20:44:21][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-22 20:44:21][com.bacon.client.App]Running
[INFO] [2017-03-22 20:46:05][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[ERROR] [2017-03-22 20:46:05][org.apache.thrift.server.TSimpleServer]Error occurred during processing of message.
com.alibaba.fastjson.JSONException: syntax error, expect {, actual error, pos 0
	at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.deserialze(JavaBeanDeserializer.java:212)
	at com.alibaba.fastjson.parser.deserializer.ASMJavaBeanDeserializer.parseRest(ASMJavaBeanDeserializer.java:96)
	at Fastjson_ASM_Parameter_1.deserialze(Unknown Source)
	at com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:514)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:244)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:220)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:179)
	at com.alibaba.fastjson.JSON.parseObject(JSON.java:327)
	at com.bacon.client.utils.JsonHandleUtils.jsonToParameterbean(JsonHandleUtils.java:32)
	at com.bacon.client.sevice.impl.ClientServiceImpl.receive(ClientServiceImpl.java:27)
	at com.bacon.client.sevice.ClientService$Processor$receive.getResult(ClientService.java:183)
	at com.bacon.client.sevice.ClientService$Processor$receive.getResult(ClientService.java:167)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.thrift.server.TSimpleServer.serve(TSimpleServer.java:80)
	at com.bacon.client.thrift.RunningServer.run(RunningServer.java:38)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[INFO] [2017-03-22 20:47:38][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-22 20:47:39][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-22 20:47:39][com.bacon.client.App]Running
[INFO] [2017-03-22 20:47:53][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-22 20:47:54][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-22 20:47:54][com.bacon.client.App]Running
[INFO] [2017-03-24 10:03:22][com.bacon.client2.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-24 10:03:22][com.bacon.client2.ServerStart]Start Server!
[INFO] [2017-03-24 10:03:22][com.bacon.client2.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-24 10:03:22][com.bacon.client2.thrift.RunningServer]Server Start Fail!
[INFO] [2017-03-24 10:03:54][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-24 10:03:54][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-24 10:03:54][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-24 10:04:03][com.bacon.client2.App]aim server ip : 127.0.0.1
aim server port : 9922
[ERROR] [2017-03-24 10:04:03][org.apache.thrift.server.TSimpleServer]Error occurred during processing of message.
java.lang.NullPointerException
	at com.bacon.client.sevice.impl.ClientServiceImpl.receive(ClientServiceImpl.java:25)
	at com.bacon.client.sevice.ClientService$Processor$receive.getResult(ClientService.java:183)
	at com.bacon.client.sevice.ClientService$Processor$receive.getResult(ClientService.java:167)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.thrift.server.TSimpleServer.serve(TSimpleServer.java:80)
	at com.bacon.client.thrift.RunningServer.run(RunningServer.java:38)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[INFO] [2017-03-24 10:06:58][com.bacon.client2.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-24 10:06:58][com.bacon.client2.ServerStart]Start Server!
[INFO] [2017-03-24 10:06:58][com.bacon.client2.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-24 10:07:06][com.bacon.client2.App]aim server ip : 127.0.0.1
aim server port : 9922
[ERROR] [2017-03-24 10:07:07][com.bacon.client2.sevice.ClientService]Unrecognized Request type
[INFO] [2017-03-24 10:07:07][com.bacon.client2.App]Unrecognized Request type
[INFO] [2017-03-24 10:08:44][com.bacon.client2.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-24 10:08:45][com.bacon.client2.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-24 10:08:45][com.bacon.client2.App]Running
[INFO] [2017-03-24 11:33:17][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-24 11:33:17][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-24 11:33:17][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-24 11:33:17][com.bacon.client.thrift.RunningServer]Server Start Fail!
[INFO] [2017-03-24 11:33:26][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[ERROR] [2017-03-24 11:33:26][org.apache.thrift.server.TSimpleServer]Error occurred during processing of message.
java.lang.NullPointerException
	at com.bacon.client2.sevice.impl.ClientServiceImpl.receive(ClientServiceImpl.java:28)
	at com.bacon.client2.sevice.ClientService$Processor$receive.getResult(ClientService.java:182)
	at com.bacon.client2.sevice.ClientService$Processor$receive.getResult(ClientService.java:166)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.thrift.server.TSimpleServer.serve(TSimpleServer.java:80)
	at com.bacon.client2.thrift.RunningServer.run(RunningServer.java:38)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[INFO] [2017-03-24 11:33:48][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-24 11:33:48][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-24 11:33:48][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-24 11:33:51][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-24 11:33:52][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-24 11:33:52][com.bacon.client.App]Running
[INFO] [2017-03-24 11:33:52][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 11:33:52][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-24 21:08:12][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-24 21:08:12][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-24 21:08:12][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-24 21:10:10][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-24 21:10:11][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-24 21:10:11][com.bacon.client.App]Running
[INFO] [2017-03-24 21:10:11][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:11][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-24 21:10:11][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:10:12][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-24 21:22:15][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-24 21:22:15][com.bacon.client.App]Running
[INFO] [2017-03-24 21:22:15][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-24 21:22:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 10:29:56][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-28 10:33:17][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-28 10:43:53][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-28 10:50:07][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-28 10:54:20][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-28 11:12:31][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-28 11:12:31][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-28 11:12:31][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-28 11:12:38][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-28 11:12:39][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-28 11:12:39][com.bacon.client.App]Running
[INFO] [2017-03-28 11:12:39][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:12:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-28 11:19:01][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-28 11:19:02][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-28 11:19:02][com.bacon.client.App]Running
[INFO] [2017-03-29 09:39:06][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 09:39:10][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-29 09:39:10][com.bacon.client.App]Running
[INFO] [2017-03-29 09:39:43][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 09:39:43][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-29 09:39:44][com.bacon.client.App]Running
[INFO] [2017-03-29 10:37:31][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 10:37:31][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 10:37:31][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 10:37:36][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 10:37:37][com.bacon.client.App]Running
[INFO] [2017-03-29 10:39:18][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 10:39:18][com.bacon.client.App]Running
[INFO] [2017-03-29 10:40:30][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 10:40:30][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 10:40:30][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 10:41:22][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 10:41:22][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 10:41:22][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 10:41:26][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 10:41:27][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 10:41:27][com.bacon.client.App]Running
[INFO] [2017-03-29 10:41:27][com.bacon.client.task.FileFutureTask]
Turn to File Upload task executor
[INFO] [2017-03-29 10:41:27][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:27][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-29 10:41:27][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:41:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:46][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 10:47:46][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 10:47:46][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 10:47:51][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 10:47:52][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 10:47:52][com.bacon.client.task.FileFutureTask]
Turn to File Upload task executor
[ERROR] [2017-03-29 10:47:52][org.apache.thrift.server.TSimpleServer]Error occurred during processing of message.
java.lang.NullPointerException
	at com.bacon.client.sevice.impl.ClientServiceImpl.receive(ClientServiceImpl.java:54)
	at com.bacon.client.sevice.ClientService$Processor$receive.getResult(ClientService.java:183)
	at com.bacon.client.sevice.ClientService$Processor$receive.getResult(ClientService.java:167)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.thrift.server.TSimpleServer.serve(TSimpleServer.java:80)
	at com.bacon.client.thrift.RunningServer.run(RunningServer.java:38)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[INFO] [2017-03-29 10:47:52][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:52][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-29 10:47:52][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:47:53][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:03][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 10:55:03][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 10:55:03][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 10:55:15][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 10:55:15][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 10:55:15][com.bacon.client.App]Running
[INFO] [2017-03-29 10:55:15][com.bacon.client.task.FileFutureTask]
Turn to File Upload task executor
[INFO] [2017-03-29 10:55:16][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:16][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-29 10:55:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 10:55:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:20][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 11:01:20][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 11:01:20][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 11:01:26][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 11:01:27][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 11:01:27][com.bacon.client.App]Running
[INFO] [2017-03-29 11:01:27][com.bacon.client.task.FileFutureTask]
Turn to File Upload task executor
[INFO] [2017-03-29 11:01:27][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:27][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-29 11:01:27][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:01:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:06:48][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 11:06:48][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 11:06:48][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 11:07:17][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 11:07:18][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 11:07:18][com.bacon.client.App]Running
[INFO] [2017-03-29 11:07:18][com.bacon.client.task.FileFutureTask]
Turn to File Upload task executor
[INFO] [2017-03-29 11:07:18][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:18][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-29 11:07:19][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:19][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:19][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:19][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:19][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:19][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:19][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:07:20][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:12:59][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 11:12:59][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 11:12:59][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 11:13:04][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 11:13:05][com.bacon.client.task.FileFutureTask]生成任务 2
[INFO] [2017-03-29 11:13:05][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 11:13:05][com.bacon.client.App]Running
[INFO] [2017-03-29 11:13:05][com.bacon.client.task.FileFutureTask]
Turn to File Upload task executor
[INFO] [2017-03-29 11:13:05][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:05][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-29 11:13:05][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:13:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:37][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 11:23:37][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 11:23:37][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 11:23:41][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 11:23:42][com.bacon.client.task.FileFutureTask]生成任务 2
[INFO] [2017-03-29 11:23:42][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 11:23:42][com.bacon.client.App]Running
[INFO] [2017-03-29 11:23:42][com.bacon.client.task.FileFutureTask]
Turn to File Upload task executor
[INFO] [2017-03-29 11:23:42][com.bacon.client.task.FileUploadTask]Here is file upload task...
[INFO] [2017-03-29 11:23:42][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:42][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:23:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:10][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 11:31:10][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 11:31:10][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 11:31:15][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 11:31:16][com.bacon.client.task.FileFutureTask]生成任务 2
[INFO] [2017-03-29 11:31:16][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 11:31:16][com.bacon.client.App]Running
[INFO] [2017-03-29 11:31:16][com.bacon.client.task.FileFutureTask]
Turn to File Upload task executor
[INFO] [2017-03-29 11:31:16][com.bacon.client.task.FileUploadTask]Here is file upload task...
[INFO] [2017-03-29 11:31:16][com.bacon.client.task.FileUploadTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:16][com.bacon.client.task.FileUploadTask]
filename: json2.txt
[INFO] [2017-03-29 11:31:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:17][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 11:31:18][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:03][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 16:56:03][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 16:56:03][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 16:56:07][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 16:56:08][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-29 16:56:08][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 16:56:08][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-29 16:56:08][com.bacon.client.App]Running
[INFO] [2017-03-29 16:56:08][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:08][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-29 16:56:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:56:09][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 16:59:56][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 16:59:56][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 16:59:56][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 17:00:00][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 17:00:02][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-29 17:00:02][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 17:00:02][com.bacon.client.App]Running
[INFO] [2017-03-29 17:00:02][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-29 17:00:02][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:02][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-29 17:00:02][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:00:03][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-29 17:00:03][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-29 17:07:33][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-29 17:07:33][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-29 17:07:33][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-29 17:07:38][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 17:07:39][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-29 17:07:39][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 17:07:39][com.bacon.client.App]Running
[INFO] [2017-03-29 17:07:39][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-29 17:07:39][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:39][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-29 17:07:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:07:40][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-29 17:07:40][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-29 17:29:58][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 17:29:59][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-29 17:29:59][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 17:29:59][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-29 17:29:59][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:29:59][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-29 17:29:59][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-29 17:35:50][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 17:35:51][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-29 17:35:51][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 17:35:51][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-29 17:35:51][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.bacon.client.App]Task Running
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:35:51][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-29 17:35:51][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-29 17:50:53][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 17:50:53][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-29 17:50:53][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 17:50:53][com.bacon.client.App]Task Running
[INFO] [2017-03-29 17:50:53][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-29 17:50:57][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-29 17:50:58][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-29 17:50:58][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-29 17:50:58][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-29 17:50:58][com.bacon.client.App]Task Running
[INFO] [2017-03-29 17:50:58][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:50:58][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-29 17:50:58][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-29 17:51:03][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-29 17:51:03][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-29 17:51:03][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 09:59:12][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-30 09:59:12][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-30 09:59:12][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-30 09:59:16][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 09:59:16][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 09:59:16][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 09:59:16][com.bacon.client.App]Task Running
[INFO] [2017-03-30 09:59:16][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 09:59:22][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 09:59:22][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 09:59:22][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 10:25:23][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 10:25:24][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 10:25:24][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 10:25:24][com.bacon.client.App]Task Running
[INFO] [2017-03-30 10:25:24][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 10:25:29][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 10:25:29][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 10:25:29][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:02:58][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:02:58][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:02:58][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:02:58][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:02:58][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:03:03][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:03:03][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:03:03][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:31:21][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-30 11:31:21][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-30 11:31:21][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-30 11:41:05][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-30 11:41:05][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-30 11:41:05][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-30 11:41:09][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:41:10][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:41:10][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:41:10][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:41:10][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:41:15][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:15][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:41:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:41:16][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:41:16][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:49:33][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:49:33][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:49:33][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:49:33][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:49:33][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:49:38][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:49:38][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:49:38][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:50:36][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:50:36][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:50:36][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:50:36][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:50:36][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:50:41][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:50:41][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:50:41][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:52:00][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:52:01][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:52:01][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:52:01][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:52:01][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:52:06][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:06][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:52:06][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:52:15][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-30 11:52:15][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-30 11:52:15][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-30 11:52:19][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:52:20][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:52:20][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:52:20][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:52:20][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:52:25][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:52:25][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:52:25][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:54:26][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-30 11:54:26][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-30 11:54:26][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-30 11:54:30][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:54:31][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:54:31][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:54:31][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:54:31][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:54:36][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:54:36][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:54:36][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:55:46][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:55:46][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:55:46][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:55:46][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:55:46][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:55:51][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:55:51][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:55:51][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:57:22][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:57:23][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:57:23][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:57:23][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:57:23][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:57:28][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:57:28][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:57:28][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 11:59:17][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 11:59:18][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 11:59:18][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 11:59:18][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 11:59:18][com.bacon.client.App]Task Running
[INFO] [2017-03-30 11:59:23][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 11:59:23][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 11:59:23][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 14:52:27][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-30 14:52:27][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-30 14:52:27][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-30 15:02:16][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-30 15:02:16][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-30 15:02:16][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-30 15:07:23][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-30 15:07:23][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-30 15:07:23][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-30 15:48:36][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 15:48:37][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 15:48:37][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 15:48:37][com.bacon.client.App]Task Running
[INFO] [2017-03-30 15:48:37][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 15:48:42][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:42][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 15:48:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:48:43][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 15:48:43][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 15:50:57][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 15:50:58][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 15:50:58][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 15:50:58][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 15:50:58][com.bacon.client.App]Task Running
[INFO] [2017-03-30 15:51:03][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 15:51:03][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 15:51:03][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 16:01:58][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-30 16:01:58][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-30 16:01:58][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-30 16:01:58][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 16:01:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490860930757}}}
[INFO] [2017-03-30 16:02:10][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 16:02:10][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 16:02:10][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 16:02:10][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 16:02:10][com.bacon.client.App]Task Running
[INFO] [2017-03-30 16:02:15][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:15][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 16:02:15][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:02:16][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 16:02:16][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 16:02:16][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 16:02:16][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-30 16:07:21][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-30 16:07:21][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-30 16:07:21][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-30 16:07:21][com.bacon.client.App]Task Running
[INFO] [2017-03-30 16:07:21][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-30 16:07:26][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json.txt
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-30 16:07:26][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-30 16:07:26][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-30 16:07:26][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-30 16:07:26][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-30 16:11:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 16:11:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490861530872}}}
[INFO] [2017-03-30 16:21:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 16:21:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490862130953}}}
[INFO] [2017-03-30 16:31:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 16:31:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490862731047}}}
[INFO] [2017-03-30 16:41:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 16:41:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490863331135}}}
[INFO] [2017-03-30 16:51:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 16:51:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490863931237}}}
[INFO] [2017-03-30 17:01:59][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 17:02:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490864531350}}}
[INFO] [2017-03-30 17:12:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 17:12:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490865131499}}}
[INFO] [2017-03-30 17:22:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 17:22:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490865731630}}}
[INFO] [2017-03-30 17:32:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 17:32:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490866331707}}}
[INFO] [2017-03-30 17:42:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 17:42:21][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 17:52:21][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 17:52:42][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 18:02:42][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 18:03:03][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 18:13:03][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 18:13:24][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 18:23:24][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 18:23:45][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 18:33:45][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 18:34:06][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 18:44:06][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 18:44:27][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 18:54:27][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 18:54:48][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 19:04:48][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 19:05:09][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 19:15:09][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 19:15:30][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 19:25:30][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 19:25:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 19:35:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 19:36:12][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 19:46:12][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 19:46:33][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 19:56:33][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 19:56:54][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 20:06:54][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 20:07:15][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 20:17:15][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 20:17:36][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 20:27:36][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 20:27:57][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 20:37:57][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 20:38:18][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 20:48:18][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 20:48:39][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 20:58:39][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 20:59:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 21:09:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 21:09:21][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 21:19:21][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 21:19:42][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 21:29:42][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 21:30:03][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 21:40:03][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 21:40:24][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 21:50:24][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 21:50:45][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 22:00:45][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 22:01:06][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 22:11:06][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 22:11:27][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 22:21:27][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 22:21:48][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 22:31:48][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 22:32:09][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 22:42:09][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 22:42:30][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 22:52:30][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 22:52:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 23:02:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 23:03:12][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 23:13:12][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 23:13:33][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 23:23:33][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 23:23:54][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 23:33:54][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 23:34:15][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 23:44:15][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 23:44:36][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-30 23:54:36][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-30 23:54:57][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 00:04:57][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 00:05:18][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 00:15:18][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 00:15:39][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 00:25:39][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 00:26:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 00:36:00][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 00:36:21][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 00:46:21][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 00:46:42][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 00:56:42][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 00:57:03][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 01:07:03][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 01:07:24][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 01:17:24][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 01:17:45][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 01:27:45][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 01:28:06][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 01:38:06][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 01:38:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 01:48:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 01:48:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 01:58:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 01:59:10][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 02:09:10][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 02:09:31][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 02:19:31][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 02:19:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 02:29:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 02:30:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 02:40:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 02:40:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 02:50:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 02:50:55][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 03:00:55][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 03:01:16][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 03:11:16][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 03:11:37][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 03:21:37][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 03:21:58][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 03:31:58][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 03:32:19][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 03:42:19][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 03:42:40][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 03:52:40][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 03:53:01][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 04:03:01][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 04:03:22][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 04:13:22][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 04:13:43][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 04:23:43][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 04:24:04][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 04:34:04][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 04:34:25][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 04:44:25][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 04:44:46][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 04:54:46][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 04:55:07][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 05:05:07][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 05:05:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 05:15:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 05:15:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 05:25:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 05:26:10][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 05:36:10][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 05:36:31][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 05:46:31][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 05:46:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 05:56:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 05:57:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 06:07:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 06:07:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 06:17:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 06:17:55][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 06:27:55][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 06:28:16][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 06:38:16][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 06:38:37][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 06:48:37][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 06:48:58][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 06:58:58][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 06:59:19][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 07:09:19][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 07:09:40][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 07:19:40][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 07:20:01][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 07:30:01][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 07:30:22][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 07:40:22][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 07:40:43][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 07:50:43][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 07:51:04][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 08:01:04][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 08:01:25][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 08:11:25][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 08:11:46][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 08:21:46][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 08:22:07][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 08:32:07][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 08:32:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 08:42:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 08:42:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 08:52:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 08:53:10][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 09:03:10][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 09:03:31][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 09:13:31][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 09:13:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 09:23:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 09:24:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 09:34:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 09:34:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 09:44:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 09:44:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490924686907}}}
[INFO] [2017-03-31 09:47:03][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 09:47:05][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 09:47:05][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 09:47:05][com.bacon.client.App]Task Running
[INFO] [2017-03-31 09:47:05][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 09:47:10][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 09:47:10][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 09:47:10][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 09:47:10][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 09:47:10][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 09:50:13][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 09:50:13][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 09:50:13][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 09:50:18][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 09:50:18][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 09:50:18][com.bacon.client.task.callable.FileUploadCallableTask]Task 13 work completely
[INFO] [2017-03-31 09:50:18][com.bacon.client.sevice.ClientService]TaskId: 13    Info: Success
[INFO] [2017-03-31 09:50:18][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 09:50:18][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 09:54:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 09:54:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490925287030}}}
[INFO] [2017-03-31 10:04:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 10:04:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490925887088}}}
[INFO] [2017-03-31 10:05:26][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 10:05:26][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 10:05:26][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 10:05:31][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 10:05:31][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 10:05:31][com.bacon.client.task.callable.FileUploadCallableTask]Task 14 work completely
[INFO] [2017-03-31 10:05:31][com.bacon.client.sevice.ClientService]TaskId: 14    Info: Success
[INFO] [2017-03-31 10:05:31][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 10:05:31][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 10:17:49][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-31 10:17:49][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-31 10:17:49][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-31 10:17:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 10:17:50][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490926682965}}}
[INFO] [2017-03-31 10:18:14][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 10:18:14][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 10:18:14][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 10:18:19][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 10:18:19][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 10:18:19][com.bacon.client.task.callable.FileUploadCallableTask]Task 15 work completely
[INFO] [2017-03-31 10:18:19][com.bacon.client.sevice.ClientService]TaskId: 15    Info: File Not Found
[INFO] [2017-03-31 10:18:19][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 10:18:20][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: 
[INFO] [2017-03-31 10:21:35][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 10:21:35][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 10:21:35][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 10:21:40][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 10:21:40][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 10:21:40][com.bacon.client.task.callable.FileUploadCallableTask]Task 16 work completely
[INFO] [2017-03-31 10:21:40][com.bacon.client.sevice.ClientService]TaskId: 16    Info: File Not Found
[INFO] [2017-03-31 10:21:40][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 10:21:40][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 10:25:56][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 10:25:56][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 10:25:56][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 10:26:01][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 10:26:01][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 10:26:01][com.bacon.client.task.callable.FileUploadCallableTask]Task 17 work completely
[INFO] [2017-03-31 10:26:01][com.bacon.client.sevice.ClientService]TaskId: 17    Info: File Not Found
[INFO] [2017-03-31 10:26:01][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 10:26:01][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 10:27:50][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 10:27:50][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490927283100}}}
[INFO] [2017-03-31 10:32:13][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 10:32:13][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 10:32:13][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 10:32:18][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 10:32:18][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 10:32:18][com.bacon.client.task.callable.FileUploadCallableTask]Task 18 work completely
[INFO] [2017-03-31 10:32:18][com.bacon.client.sevice.ClientService]TaskId: 18    Info: File Not Found
[INFO] [2017-03-31 10:32:18][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 10:32:19][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 10:37:50][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 10:37:50][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490927883184}}}
[INFO] [2017-03-31 10:47:50][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 10:47:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490928483304}}}
[INFO] [2017-03-31 10:57:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 10:57:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490929083472}}}
[INFO] [2017-03-31 10:58:18][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 10:58:18][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 10:58:18][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 10:58:23][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 10:58:23][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 10:58:23][com.bacon.client.task.callable.FileUploadCallableTask]Task 19 work completely
[INFO] [2017-03-31 10:58:23][com.bacon.client.sevice.ClientService]TaskId: 19    Info: File Not Found
[INFO] [2017-03-31 10:58:23][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 10:58:23][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: File Not Found 19
[INFO] [2017-03-31 11:00:28][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 11:00:28][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 11:00:28][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 11:00:33][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 11:00:33][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 11:00:33][com.bacon.client.task.callable.FileUploadCallableTask]Task 20 work completely
[INFO] [2017-03-31 11:00:33][com.bacon.client.sevice.ClientService]TaskId: 20    Info: File Not Found
[INFO] [2017-03-31 11:00:33][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 11:00:33][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: File Not Found 20
[INFO] [2017-03-31 11:01:22][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 11:01:22][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 11:01:22][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 11:01:27][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 11:01:27][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 11:01:27][com.bacon.client.task.callable.FileUploadCallableTask]Task 21 work completely
[INFO] [2017-03-31 11:01:27][com.bacon.client.sevice.ClientService]TaskId: 21    Info: File Not Found
[INFO] [2017-03-31 11:01:27][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 11:01:27][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: File Not Found 21
[INFO] [2017-03-31 11:02:00][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 11:02:00][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 11:02:00][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 11:02:05][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 11:02:05][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 11:02:05][com.bacon.client.task.callable.FileUploadCallableTask]Task 22 work completely
[INFO] [2017-03-31 11:02:05][com.bacon.client.sevice.ClientService]TaskId: 22    Info: File Not Found
[INFO] [2017-03-31 11:02:05][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 11:02:06][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 11:06:29][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 11:06:29][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 11:06:29][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 11:06:34][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"/home/bacon/test","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 11:06:34][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-03-31 11:06:34][com.bacon.client.task.callable.FileUploadCallableTask]Task 23 work completely
[INFO] [2017-03-31 11:06:34][com.bacon.client.sevice.ClientService]TaskId: 23    Info: File Not Found
[INFO] [2017-03-31 11:06:34][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 11:06:34][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: File Not Found 23
[INFO] [2017-03-31 11:07:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 11:07:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490929683572}}}
[INFO] [2017-03-31 11:17:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 11:17:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490930283787}}}
[INFO] [2017-03-31 11:18:34][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 11:18:34][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 11:18:34][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 11:18:39][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 11:18:39][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 11:18:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"1234567890123456","blacklist":["name","age"],"dbname":"db_test","fieldregex":["\\w*","\\w*","\\w*"],"filedname":["name","name2","name3"],"filednameencryptedlist":["name","age"],"filednamesplitedlist":["name","age"],"isallstring":true,"isencrypted":true,"ispart":true,"isregexed":true,"issplited":true,"iswholedb":true,"iswholetable":true,"originstr":"123|456","path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":1,"splitsymbol":",","tablename":"table_test","topic":"test","whitelist":["name","age"]}
[INFO] [2017-03-31 11:20:33][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 11:20:34][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 11:20:34][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 11:20:34][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 11:20:34][com.bacon.client.App]Task Running
[INFO] [2017-03-31 11:20:39][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:20:39][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 11:20:39][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 11:20:39][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 11:20:39][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: Success 2
[INFO] [2017-03-31 11:27:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 11:27:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490930883876}}}
[INFO] [2017-03-31 11:34:28][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 11:34:28][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 11:34:28][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 11:34:33][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:34:33][com.bacon.client.task.callable.FileUploadCallableTask]Task 26 work completely
[INFO] [2017-03-31 11:34:33][com.bacon.client.sevice.ClientService]TaskId: 26    Info: Success
[INFO] [2017-03-31 11:34:33][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 11:34:33][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: Success 26
[INFO] [2017-03-31 11:37:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 11:37:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490931483959}}}
[INFO] [2017-03-31 11:46:41][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 11:46:41][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 11:46:41][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 11:46:46][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 11:46:46][com.bacon.client.task.callable.FileUploadCallableTask]Task 27 work completely
[INFO] [2017-03-31 11:46:46][com.bacon.client.sevice.ClientService]TaskId: 27    Info: Success
[INFO] [2017-03-31 11:46:46][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 11:46:46][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: Success 27
[INFO] [2017-03-31 11:47:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 11:47:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490932084048}}}
[INFO] [2017-03-31 11:57:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 11:57:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490932684182}}}
[INFO] [2017-03-31 12:07:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 12:07:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490933284308}}}
[INFO] [2017-03-31 12:17:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 12:17:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490933884414}}}
[INFO] [2017-03-31 12:27:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 12:27:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490934484527}}}
[INFO] [2017-03-31 12:37:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 12:37:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490935084630}}}
[INFO] [2017-03-31 12:47:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 12:47:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490935684725}}}
[INFO] [2017-03-31 12:57:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 12:57:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490936284832}}}
[INFO] [2017-03-31 13:07:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 13:07:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490936884947}}}
[INFO] [2017-03-31 13:17:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 13:17:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490937485066}}}
[INFO] [2017-03-31 13:27:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 13:27:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: {"code":0,"datas":{"alivelist":{"125.216.243.200_8080":1490938085159}}}
[INFO] [2017-03-31 13:30:36][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 13:30:36][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 13:30:36][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 13:30:41][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:30:41][com.bacon.client.task.callable.FileUploadCallableTask]Task 28 work completely
[INFO] [2017-03-31 13:30:41][com.bacon.client.sevice.ClientService]TaskId: 28    Info: Success
[INFO] [2017-03-31 13:30:41][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 13:30:41][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 13:32:37][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 13:32:37][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 13:32:37][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 13:32:42][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:32:42][com.bacon.client.task.callable.FileUploadCallableTask]Task 29 work completely
[INFO] [2017-03-31 13:32:42][com.bacon.client.sevice.ClientService]TaskId: 29    Info: Success
[INFO] [2017-03-31 13:32:42][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 13:32:42][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: 29 Success
[INFO] [2017-03-31 13:37:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 13:38:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 13:48:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 13:48:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 13:57:41][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-31 13:57:41][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-31 13:57:41][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-31 13:57:41][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 13:58:00][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 13:58:01][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 13:58:01][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 13:58:01][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 13:58:01][com.bacon.client.App]Task Running
[INFO] [2017-03-31 13:58:04][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 13:58:06][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:58:06][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 13:58:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:58:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 13:58:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 13:58:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 13:58:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 13:58:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 13:58:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 13:59:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 13:59:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 13:59:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 13:59:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 13:59:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 13:59:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 13:59:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:00:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:00:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:00:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:00:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:00:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:00:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:00:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:01:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:01:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:01:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:01:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:01:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-4
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:01:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:01:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:02:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:02:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:02:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:02:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:02:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-5
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:02:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:02:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:03:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:03:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:03:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:03:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:03:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-6
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:03:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:03:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:04:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:04:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:04:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:04:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:04:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-7
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:04:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:04:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:05:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:05:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:05:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:05:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:05:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-8
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:05:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:05:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:06:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:06:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:06:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:06:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:06:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-9
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:06:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:06:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:07:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:07:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:07:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:07:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:07:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-10
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:07:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:07:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:08:04][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 14:08:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:08:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:08:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:08:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:08:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-11
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:08:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:08:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:08:25][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 14:09:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:09:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:09:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:09:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:09:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-12
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:09:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:09:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:10:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:10:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:10:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:10:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:10:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-13
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:10:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:10:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:11:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:11:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:11:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:11:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:11:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-14
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:11:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:11:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:12:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:12:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:12:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:12:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:12:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-15
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:12:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:12:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:13:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:13:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:13:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:13:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:13:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-16
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:13:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:13:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:14:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:14:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:14:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:14:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:14:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-17
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:14:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:14:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:15:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:15:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:15:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:15:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:15:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-18
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:15:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:15:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:16:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:16:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:16:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:16:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:16:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-19
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:16:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:16:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:17:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:17:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:17:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:17:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:17:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-20
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:17:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:17:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:18:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:18:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:18:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:18:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:18:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-21
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:18:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:18:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:18:25][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 14:18:46][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 14:19:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-22
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:20:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-23
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:21:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:21:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:21:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:21:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:21:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-24
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:21:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:21:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:22:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:22:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:22:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:22:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:22:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-25
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:22:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:22:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:23:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:23:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:23:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:23:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:23:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-26
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:23:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:23:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:24:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:24:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:24:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:24:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:24:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-27
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:24:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:24:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:25:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:25:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:25:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:25:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:25:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-28
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:25:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:25:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:26:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:26:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:26:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:26:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:26:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-29
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:26:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:26:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:27:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:27:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:27:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:27:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:27:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-30
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:27:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:27:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:28:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:28:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:28:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:28:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:28:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-31
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:28:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:28:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:28:46][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 14:29:07][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 14:29:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:29:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:29:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:29:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:29:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-32
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:29:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:29:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:30:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:30:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:30:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:30:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:30:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-33
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:30:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:30:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:31:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:31:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:31:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:31:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:31:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-34
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:31:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:31:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:32:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:32:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:32:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:32:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:32:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-35
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:32:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:32:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:33:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:33:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:33:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:33:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:33:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-36
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:33:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:33:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:34:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:34:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:34:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:34:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:34:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-37
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:34:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:34:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:35:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:35:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:35:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:35:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:35:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-38
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:35:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:35:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:36:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:36:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:36:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:36:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:36:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-39
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:36:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:36:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:37:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:37:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:37:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:37:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:37:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-40
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:37:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:37:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:38:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:38:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:38:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:38:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:38:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-41
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:38:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:38:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:39:07][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 14:39:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:39:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:39:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:39:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:39:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-42
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:39:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:39:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:39:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 14:40:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:40:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:40:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:40:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:40:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-43
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:40:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:40:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:41:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:41:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:41:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:41:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:41:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-44
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:41:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:41:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:42:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:42:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:42:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:42:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:42:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-45
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:42:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:42:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:43:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:43:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:43:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:43:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:43:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-46
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:43:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:43:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:44:08][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 14:44:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:44:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:44:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 14:44:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-47
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 14:44:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 14:44:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 14:45:08][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 14:45:08][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 14:45:08][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 14:45:29][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 14:49:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 14:49:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 14:59:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 15:00:10][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 15:10:10][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 15:10:31][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 15:20:31][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 15:20:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 15:30:52][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 15:31:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 15:41:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 15:41:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 15:51:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 15:51:55][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 16:01:55][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 16:02:16][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 16:12:16][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 16:12:37][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 16:22:37][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 16:22:58][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 16:28:00][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 16:28:01][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 16:28:01][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 16:28:01][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 16:28:01][com.bacon.client.App]Task Running
[INFO] [2017-03-31 16:28:06][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:28:06][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 16:28:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:28:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:28:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:28:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:28:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-48
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:28:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 16:28:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 16:29:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:29:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:29:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:29:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:29:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-49
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:29:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 16:29:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 16:30:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:30:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:30:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:30:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:30:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-50
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:30:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 16:30:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 16:31:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:31:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:31:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:31:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:31:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-51
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:31:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 16:31:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 16:32:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:32:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:32:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:32:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:32:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-52
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:32:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 16:32:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 16:32:58][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 16:33:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:33:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:33:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:33:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:33:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-53
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:33:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 16:33:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 16:33:19][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 16:34:06][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:34:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:34:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:34:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 16:34:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-54
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 16:34:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 16:34:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[WARN] [2017-03-31 16:34:41][org.apache.kafka.common.protocol.Errors]Unexpected error code: 38.
[WARN] [2017-03-31 16:34:41][org.apache.kafka.common.protocol.Errors]Unexpected error code: 38.
[WARN] [2017-03-31 16:34:41][org.apache.kafka.common.protocol.Errors]Unexpected error code: 38.
[WARN] [2017-03-31 16:34:41][org.apache.kafka.common.protocol.Errors]Unexpected error code: 38.
[WARN] [2017-03-31 16:34:41][org.apache.kafka.common.protocol.Errors]Unexpected error code: 38.
[WARN] [2017-03-31 16:34:41][org.apache.kafka.common.protocol.Errors]Unexpected error code: 38.
[WARN] [2017-03-31 16:34:41][org.apache.kafka.common.protocol.Errors]Unexpected error code: 38.
[WARN] [2017-03-31 16:34:41][org.apache.kafka.common.protocol.Errors]Unexpected error code: 38.
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=UNKNOWN}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=UNKNOWN}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=UNKNOWN}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=UNKNOWN}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=UNKNOWN}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=UNKNOWN}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=UNKNOWN}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=UNKNOWN}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:41][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 2 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[WARN] [2017-03-31 16:34:42][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 1 : {test=LEADER_NOT_AVAILABLE}
[INFO] [2017-03-31 16:42:27][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-31 16:42:27][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-31 16:42:27][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-31 16:42:27][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 16:42:34][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 16:42:35][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 16:42:35][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 16:42:35][com.bacon.client.App]Task Running
[INFO] [2017-03-31 16:42:35][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 16:42:40][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:40][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 16:42:40][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":false,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:42:41][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 16:42:41][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 16:42:41][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 16:42:50][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 16:43:02][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 16:48:14][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 16:48:14][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 16:48:14][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 16:48:14][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 16:48:14][com.bacon.client.App]Task Running
[INFO] [2017-03-31 16:48:19][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aesprikey":"123456","isallstring":false,"isencrypted":true,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:48:19][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 16:48:19][com.b3434.Factory.ProcessorFactory]parameter={"aesprikey":"123456","isallstring":false,"isencrypted":true,"ispart":false,"isregexed":false,"issplited":false,"iswholedb":false,"iswholetable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securitylevel":2,"topic":"test"}
[INFO] [2017-03-31 16:49:51][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-31 16:49:51][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-31 16:49:51][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-31 16:49:51][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 16:49:55][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 16:49:55][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 16:49:55][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 16:49:55][com.bacon.client.App]Task Running
[INFO] [2017-03-31 16:49:55][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 16:50:01][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":true,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 16:50:01][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 16:50:01][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":true,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 16:50:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 16:54:40][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 16:54:40][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 16:54:40][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 16:54:40][com.bacon.client.App]Task Running
[INFO] [2017-03-31 16:54:40][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 16:54:45][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":true,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 16:54:45][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 16:54:45][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":true,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 16:57:38][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 16:57:39][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 16:57:39][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 16:57:39][com.bacon.client.App]Task Running
[INFO] [2017-03-31 16:57:39][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 16:57:44][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":true,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 16:57:44][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 16:57:44][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":true,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:00:13][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 17:00:34][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 17:01:10][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:01:11][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 17:01:11][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 17:01:11][com.bacon.client.App]Task Running
[INFO] [2017-03-31 17:01:11][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 17:01:16][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:01:16][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 17:01:16][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 17:01:16][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 17:01:37][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 17:07:45][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-31 17:07:45][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-31 17:07:45][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-31 17:07:45][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 17:07:50][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:07:50][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 17:07:50][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 17:07:50][com.bacon.client.App]Task Running
[INFO] [2017-03-31 17:07:50][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 17:07:55][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:07:55][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 17:07:55][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:07:56][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 17:07:56][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 17:07:56][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 17:08:07][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 17:08:17][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 17:10:10][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:10:10][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 17:10:10][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 17:10:10][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 17:10:10][com.bacon.client.App]Task Running
[INFO] [2017-03-31 17:10:15][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:10:15][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 17:10:15][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:10:15][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 17:10:15][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 17:10:15][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 17:10:36][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 17:12:04][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:12:04][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 17:12:04][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 17:12:04][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 17:12:04][com.bacon.client.App]Task Running
[INFO] [2017-03-31 17:12:09][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:12:09][com.bacon.client.task.callable.FileUploadCallableTask]
filename: json2.txt
[INFO] [2017-03-31 17:12:09][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\json2.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:12:09][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 17:12:09][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 17:12:09][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 17:12:30][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 17:15:14][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:15:14][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 17:15:14][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 17:15:14][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 17:15:14][com.bacon.client.App]Task Running
[INFO] [2017-03-31 17:15:19][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:15:19][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-03-31 17:15:19][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:17:12][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:17:42][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:17:58][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-31 17:17:58][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-31 17:17:58][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-31 17:17:58][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 17:18:03][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:18:04][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 17:18:04][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 17:18:04][com.bacon.client.App]Task Running
[INFO] [2017-03-31 17:18:04][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 17:18:09][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:18:09][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-03-31 17:18:09][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:18:54][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-31 17:18:54][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-31 17:18:54][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-31 17:18:54][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 17:18:59][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:19:00][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 17:19:00][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 17:19:00][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 17:19:00][com.bacon.client.App]Task Running
[INFO] [2017-03-31 17:19:05][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:19:05][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-03-31 17:19:05][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:19:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[WARN] [2017-03-31 17:19:06][org.apache.kafka.clients.NetworkClient]Error while fetching metadata with correlation id 0 : {test=LEADER_NOT_AVAILABLE}
[INFO] [2017-03-31 17:19:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:07][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:07][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:07][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:07][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-4
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:07][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:07][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-5
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-6
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-7
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-8
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-9
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-10
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-11
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-12
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-13
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-14
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:10][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:10][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-15
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:10][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:10][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-16
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:10][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:10][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-17
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:10][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:10][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-18
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-19
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-20
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-21
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-22
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-23
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-24
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-25
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-26
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-27
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-28
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-29
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-30
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-31
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-32
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-33
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-34
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-35
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-36
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-37
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-38
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-39
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-40
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-41
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-42
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-43
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-44
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:16][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-45
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:16][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-46
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-47
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-48
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-49
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-50
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-51
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-52
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-53
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-54
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-55
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:19][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:19][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-56
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:19][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:19][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-57
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:19][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:19][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-58
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:19][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:19][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-59
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-60
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-61
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-62
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-63
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:20][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-64
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-65
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-66
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-67
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-68
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-69
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-70
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-71
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-72
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-73
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-74
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-75
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-76
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-77
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-78
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-79
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-80
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-81
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-82
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-83
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-84
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-85
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-86
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-87
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:26][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:26][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-88
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:26][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:26][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-89
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:26][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:26][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-90
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:26][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:26][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-91
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:27][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:27][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-92
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:27][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:27][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-93
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:27][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:27][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-94
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:27][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:27][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-95
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-96
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-97
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-98
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-99
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-100
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-101
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-102
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-103
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-104
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-105
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-106
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-107
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-108
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-109
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-110
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-111
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-112
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-113
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:31][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-114
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-115
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-116
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-117
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-118
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:32][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-119
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:33][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:33][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-120
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:33][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:33][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-121
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:33][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:33][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-122
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:33][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:33][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-123
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-124
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-125
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-126
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:34][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-127
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:34][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:35][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:35][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:35][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:35][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-128
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:35][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:35][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:35][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:35][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:35][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:35][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-129
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:35][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:35][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:35][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:35][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:35][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:35][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-130
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:35][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:35][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:35][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:35][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:35][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:35][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-131
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:35][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:35][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-132
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-133
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-134
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-135
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:36][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-136
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:36][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-137
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-138
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-139
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-140
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-141
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:37][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:38][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:38][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:38][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:38][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-142
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:38][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:38][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:38][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:38][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:38][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:38][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-143
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:38][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:38][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:38][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:38][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:38][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:38][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-144
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:38][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:38][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:38][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:38][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:38][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:38][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-145
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:38][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:38][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-146
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-147
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-148
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-149
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-150
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:39][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-151
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-152
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-153
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-154
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-155
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:40][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-156
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-157
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-158
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-159
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-160
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-161
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-162
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-163
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:42][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-164
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:42][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-165
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-166
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-167
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-168
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-169
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:43][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:44][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:44][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-170
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:44][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:44][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:44][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:44][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-171
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:44][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:44][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:44][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:44][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-172
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:44][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:44][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:44][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:44][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-173
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:44][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:44][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-174
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-175
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-176
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-177
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:45][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-178
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:45][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:46][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:46][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:46][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:46][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-179
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:46][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:46][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:46][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:46][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:46][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:46][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-180
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:46][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:46][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:46][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:46][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:46][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:46][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-181
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:46][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:46][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:46][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:46][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:46][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:46][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-182
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:46][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:46][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-183
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-184
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-185
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-186
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-187
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:47][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-188
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-189
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-190
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-191
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:48][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-192
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:48][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:49][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:49][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:49][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:49][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-193
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:49][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:49][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:49][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:49][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:49][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:49][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-194
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:49][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:49][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:49][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:49][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:49][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:49][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-195
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:49][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:49][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:49][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:49][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:49][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:49][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-196
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:49][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:49][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-197
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-198
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-199
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-200
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:50][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-201
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:50][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:51][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:51][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:51][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:51][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-202
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:51][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:51][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:51][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:51][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:51][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:51][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-203
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:51][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:51][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:51][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:51][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:51][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:51][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-204
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:51][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:51][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:51][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:51][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:51][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:51][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-205
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:51][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:51][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-206
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-207
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-208
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-209
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-210
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:52][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:53][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:53][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:53][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:53][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-211
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:53][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:53][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:53][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:53][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:53][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:53][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-212
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:53][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:53][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:53][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:53][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:53][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:53][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-213
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:53][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:53][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:53][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:53][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:53][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:53][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-214
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:53][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:53][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-215
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-216
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-217
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-218
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:54][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-219
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:54][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-220
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-221
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-222
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-223
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:55][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-224
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:55][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:56][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:56][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:56][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:56][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-225
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:56][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:56][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:56][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:56][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:56][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:56][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-226
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:56][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:56][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:56][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:56][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:56][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:56][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-227
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:56][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:56][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:56][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:56][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:56][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:56][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-228
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:56][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:56][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-229
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-230
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-231
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-232
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:57][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-233
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:57][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-234
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-235
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-236
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-237
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:58][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-238
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:58][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:59][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:59][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:59][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:59][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-239
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:59][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:59][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:59][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:59][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:59][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:59][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-240
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:59][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:59][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:59][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:59][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:59][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:59][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-241
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:59][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:59][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:19:59][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:59][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:59][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:19:59][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-242
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:19:59][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:19:59][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-243
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-244
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-245
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-246
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:00][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-247
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:00][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-248
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-249
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-250
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-251
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:01][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-252
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:01][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-253
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:02][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:02][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-254
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:02][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:02][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-255
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:02][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:02][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-256
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:02][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:02][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-257
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-258
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-259
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-260
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:03][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-261
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:03][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-262
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-263
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-264
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-265
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:04][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-266
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:04][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:05][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:05][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:05][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:05][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-267
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:05][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:05][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:05][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:05][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:05][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:05][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-268
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:05][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:05][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:05][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:05][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:05][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:05][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-269
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:05][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:05][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:05][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:05][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:05][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:05][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-270
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:05][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:05][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-271
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-272
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-273
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-274
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-275
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-276
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-277
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-278
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-279
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:07][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-280
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:07][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-281
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-282
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-283
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-284
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-285
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-286
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-287
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-288
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-289
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-290
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-291
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-292
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-293
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-294
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:10][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-295
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-296
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-297
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-298
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-299
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-300
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-301
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-302
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-303
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-304
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-305
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-306
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-307
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-308
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-309
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-310
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-311
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:14][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-312
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:14][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-313
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-314
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-315
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-316
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:15][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-317
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:15][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-318
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:16][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:16][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-319
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:16][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:16][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-320
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:16][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:16][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:16][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-321
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:16][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:16][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:16][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-322
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-323
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-324
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-325
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-326
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-327
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-328
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-329
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-330
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:18][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-331
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:18][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-332
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-333
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-334
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-335
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-336
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:19][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-337
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:20][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:20][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-338
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:20][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:20][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-339
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:20][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:20][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:20][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-340
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:20][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:20][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-341
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-342
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-343
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-344
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-345
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-346
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-347
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-348
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-349
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-350
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-351
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-352
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-353
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-354
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-355
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-356
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-357
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-358
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-359
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-360
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-361
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-362
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-363
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:25][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-364
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:25][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-365
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:26][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:26][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-366
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:26][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:26][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-367
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:26][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:26][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:26][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:26][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-368
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:26][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:26][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-369
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-370
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-371
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-372
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:27][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-373
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:27][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-374
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-375
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-376
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-377
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-378
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:28][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-379
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-380
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-381
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-382
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-383
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-384
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-385
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-386
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-387
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-388
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:31][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:31][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:20:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:31][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:20:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-389
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:20:31][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:20:31][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:29:06][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-31 17:29:06][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-31 17:29:06][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-31 17:29:06][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 17:29:10][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:29:11][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 17:29:11][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 17:29:11][com.bacon.client.App]Task Running
[INFO] [2017-03-31 17:29:11][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 17:29:16][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:29:16][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-03-31 17:29:16][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:29:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:29:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:29:17][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:29:17][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:29:17][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:29:17][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:29:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 17:30:15][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 17:30:15][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 17:30:15][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 17:30:36][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 17:39:28][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 17:39:49][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 17:48:20][com.bacon.client.utils.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-03-31 17:48:20][com.bacon.client.ServerStart]Start Server!
[INFO] [2017-03-31 17:48:20][com.bacon.client.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-03-31 17:48:20][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 17:48:25][com.bacon.client.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-03-31 17:48:26][com.bacon.client.sevice.ClientService]
Turn to File Upload task executor
[INFO] [2017-03-31 17:48:26][com.bacon.client.sevice.ClientService]
Executing future task...
[INFO] [2017-03-31 17:48:26][com.bacon.client.App]Task Running
[INFO] [2017-03-31 17:48:26][com.bacon.client.task.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-03-31 17:48:31][com.bacon.client.task.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:48:31][com.bacon.client.task.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-03-31 17:48:31][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-03-31 17:48:31][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:48:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:48:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-03-31 17:48:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-03-31 17:48:32][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-03-31 17:48:32][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-03-31 17:48:42][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-03-31 17:49:34][com.bacon.client.task.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-03-31 17:49:34][com.bacon.client.sevice.ClientService]TaskId: 2    Info: Success
[INFO] [2017-03-31 17:49:34][com.bacon.client.task.httpTasks.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-03-31 17:49:55][com.bacon.client.task.httpTasks.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-03-31 17:58:42][com.bacon.client.task.httpTasks.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-03-31 17:59:03][com.bacon.client.task.httpTasks.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 14:25:09][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 14:25:09][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 14:25:09][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 14:25:09][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 14:25:31][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 14:35:31][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 14:35:52][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 14:37:36][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 14:37:36][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 14:37:36][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 14:37:36][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 14:37:50][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 14:37:51][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 14:37:51][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 14:37:51][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 14:37:51][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 14:37:51][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 14:37:51][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 14:37:51][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 14:37:57][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 14:47:57][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 14:48:18][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 14:53:13][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 14:53:13][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 14:53:13][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 14:53:13][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 14:53:17][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 14:53:17][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 14:53:17][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 14:53:17][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 14:53:17][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 14:53:17][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 14:53:17][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 14:53:17][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 14:53:35][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 14:56:53][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 14:56:53][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 14:56:53][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 14:56:53][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 14:56:56][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 14:56:57][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 14:56:57][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 14:56:57][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 14:56:57][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 14:56:57][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 14:56:57][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 14:56:57][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 14:57:15][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:01:37][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 15:01:37][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 15:01:37][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 15:01:37][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 15:01:42][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 15:01:43][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 15:01:43][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 15:01:43][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 15:01:43][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:01:43][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 15:01:43][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 15:01:43][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 15:01:58][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:04:10][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 15:04:10][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 15:04:10][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 15:04:10][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 15:04:13][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 15:04:13][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 15:04:13][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 15:04:13][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 15:04:13][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 15:04:13][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 15:04:14][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:04:14][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 15:04:32][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:06:28][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 15:06:28][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 15:06:28][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 15:06:28][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 15:06:40][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 15:06:40][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 15:06:40][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 15:06:40][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 15:06:40][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 15:06:40][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 15:06:40][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:06:40][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 15:06:49][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:08:49][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 15:08:49][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 15:08:49][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 15:08:49][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 15:08:52][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 15:08:53][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 15:08:53][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 15:08:53][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 15:08:53][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 15:08:53][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 15:08:53][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:08:53][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 15:09:11][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:10:40][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 15:10:40][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 15:10:40][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 15:10:40][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 15:10:44][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 15:10:45][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 15:10:45][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 15:10:45][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 15:10:45][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 15:10:45][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 15:10:45][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:10:45][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 15:11:02][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:12:21][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 15:12:21][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 15:12:21][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 15:12:21][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 15:12:24][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 15:12:24][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 15:12:24][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 15:12:24][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 15:12:24][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 15:12:24][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 15:12:24][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:12:24][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 15:12:43][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:15:11][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 15:15:11][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 15:15:11][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 15:15:11][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 15:15:14][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 15:15:14][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 15:15:14][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 15:15:14][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 15:15:14][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 15:15:14][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 15:15:14][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:15:14][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 15:15:33][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:17:37][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 15:17:37][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 15:17:37][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 15:17:37][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 15:17:41][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 15:17:41][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 15:17:41][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 15:17:41][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 15:17:41][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 15:17:41][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 15:17:41][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:17:41][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 15:17:58][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:27:12][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-06 15:27:12][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-06 15:27:12][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-06 15:27:12][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-06 15:27:18][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-06 15:27:18][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor
[INFO] [2017-04-06 15:27:18][com.bacon.client.common.service.ClientService]
Executing future task...
[INFO] [2017-04-06 15:27:18][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-06 15:27:19][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-06 15:27:19][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-06 15:27:19][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:27:19][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-06 15:27:19][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-06 15:27:19][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-06 15:27:20][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-06 15:27:21][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-06 15:27:21][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-06 15:27:21][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-06 15:27:21][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-06 15:27:34][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-06 15:27:35][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-06 15:27:35][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-06 15:27:35][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-06 15:27:56][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 10:59:02][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 10:59:02][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 10:59:02][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 10:59:02][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 10:59:11][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 10:59:12][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 10:59:12][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 10:59:12][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-04-07 10:59:12][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 10:59:12][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test
[INFO] [2017-04-07 10:59:12][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 10:59:12][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 10:59:12][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 10:59:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 10:59:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 10:59:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 10:59:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 10:59:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 10:59:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 10:59:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 10:59:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 10:59:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 10:59:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 10:59:13][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 10:59:13][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 10:59:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 10:59:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 10:59:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 10:59:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 10:59:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 10:59:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 10:59:13][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 10:59:13][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 10:59:13][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 10:59:13][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 0   File Not Found
[INFO] [2017-04-07 10:59:13][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 1   File Not Found
[INFO] [2017-04-07 10:59:13][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 2   File Not Found
[INFO] [2017-04-07 10:59:13][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Error
[INFO] [2017-04-07 10:59:13][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 10:59:24][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 10:59:34][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 11:04:07][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 11:04:07][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 11:04:07][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 11:04:07][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 11:04:10][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 11:04:11][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 11:04:11][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:04:11][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-07 11:04:11][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 11:04:11][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 11:04:11][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:04:11][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 11:04:11][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:04:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:04:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:04:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:04:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:04:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:04:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:04:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:04:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:04:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:04:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:04:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:04:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:04:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:04:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:04:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:04:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:04:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:04:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:04:29][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 11:14:29][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 11:14:50][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 11:16:39][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 11:16:39][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 11:16:39][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 11:16:39][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 11:17:01][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 11:17:40][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 11:17:40][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 11:17:40][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:17:40][com.bacon.client.common.service.ClientService]return {"folder":true} to request
[INFO] [2017-04-07 11:17:40][com.bacon.client.api.app.App]{"folder":true}
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 11:17:40][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 11:17:40][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:17:40][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:17:40][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:17:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:17:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:17:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:17:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:17:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:17:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:17:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:17:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:17:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:17:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:17:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:17:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:17:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:17:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:17:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:17:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:17:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:17:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:19:06][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 11:19:06][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 11:19:06][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 11:19:06][com.bacon.client.common.service.ClientService]return {"folder":true} to request
[INFO] [2017-04-07 11:19:06][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 11:19:06][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:19:06][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:19:06][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 11:19:06][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:19:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:19:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:19:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:19:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-4
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:19:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:19:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:19:06][com.bacon.client.api.app.App]{"folder":true}
[INFO] [2017-04-07 11:26:35][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 11:26:35][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 11:26:35][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 11:26:35][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 11:26:39][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 11:26:40][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 11:26:40][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 11:26:40][com.bacon.client.common.service.ClientService]return {"folder":true} to request
[INFO] [2017-04-07 11:26:40][com.bacon.client.api.app.App]{"folder":true}
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:26:40][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 11:26:40][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:26:40][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:26:40][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:26:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:26:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:26:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:26:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:26:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:26:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:26:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:26:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:26:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:26:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:26:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:26:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:26:41][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:26:41][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:26:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:26:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:26:41][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:26:41][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:26:57][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 11:27:23][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 11:27:24][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 11:27:24][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 11:27:24][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 0   Success
[INFO] [2017-04-07 11:27:24][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 1   Success
[INFO] [2017-04-07 11:27:24][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 2   Success
[INFO] [2017-04-07 11:27:24][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Error
[INFO] [2017-04-07 11:27:24][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 11:27:45][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 11:33:51][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 11:33:52][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 11:33:52][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 11:33:52][com.bacon.client.common.service.ClientService]return {"folder":true} to request
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:33:52][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 11:33:52][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 11:33:52][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:33:52][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:33:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:33:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:33:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:33:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:33:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:33:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:33:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-6
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:33:52][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:33:52][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:33:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:33:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-5
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:33:52][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:33:52][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:33:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:33:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:33:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-4
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:33:52][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:33:52][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:33:52][com.bacon.client.api.app.App]{"folder":true}
[INFO] [2017-04-07 11:34:53][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 11:34:53][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 11:34:53][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 11:34:53][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 11:35:14][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 11:36:09][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 11:36:10][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 11:36:10][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 11:36:10][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 11:36:10][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-07 11:36:10][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-07 11:36:10][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:36:10][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 11:36:10][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 11:36:10][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:36:10][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:36:11][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 11:36:11][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 11:36:11][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 11:36:11][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 11:45:19][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 11:45:40][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 11:55:40][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 11:56:01][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 12:06:01][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 12:06:22][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 12:16:22][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 12:16:43][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 12:26:43][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 12:27:04][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 12:37:04][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 12:37:25][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 12:47:25][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 12:47:46][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 12:57:17][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 12:57:17][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 12:57:17][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 12:57:17][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 12:57:21][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 12:57:21][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 12:57:21][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 12:57:21][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 12:57:21][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-07 12:57:21][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-07 12:57:21][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 12:57:21][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 12:57:21][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 12:57:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 12:57:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 12:57:22][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 12:57:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 12:57:22][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 12:57:22][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 12:57:39][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 12:58:31][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 12:58:31][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 12:58:31][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 12:58:31][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 12:58:38][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 12:58:39][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 12:58:39][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 12:58:39][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 12:58:39][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-07 12:58:39][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-07 12:58:39][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 12:58:39][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 12:58:39][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 12:58:39][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 12:58:39][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 12:58:40][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 12:58:40][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 12:58:40][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 12:58:40][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 12:58:53][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 13:08:53][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 13:09:14][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 13:20:37][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 13:20:37][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 13:20:37][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 13:20:37][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 13:20:59][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 13:21:04][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 13:21:04][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 13:21:04][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 13:21:04][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 13:21:04][com.bacon.client.common.service.ClientService]return {"folder":false} to request
[INFO] [2017-04-07 13:21:04][com.bacon.client.api.app.App]{"folder":false}
[INFO] [2017-04-07 13:21:04][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 13:21:04][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 13:21:04][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 13:21:05][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 13:21:05][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 13:21:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 13:21:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 13:21:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 13:21:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 13:21:37][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 13:21:37][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 13:21:37][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 13:21:47][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 13:21:47][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 13:21:47][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 13:21:47][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 13:22:09][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 13:22:10][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 13:22:11][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 13:22:11][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 13:22:11][com.bacon.client.common.service.ClientService]return {"folder":true} to request
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 13:22:11][com.bacon.client.api.app.App]{"folder":true}
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 13:22:11][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 13:22:11][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 13:22:11][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 13:22:11][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 13:22:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 13:22:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 13:22:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 13:22:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 13:22:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 13:22:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 13:22:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 13:22:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 13:22:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 13:22:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 13:22:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 13:22:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 13:22:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 13:22:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 13:22:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 13:22:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 13:22:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 13:22:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 13:22:57][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 13:22:58][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 13:22:58][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 0   Success
[INFO] [2017-04-07 13:22:59][com.bacon.client.core.callable.FileUploadCallableTask]Task 2 work completely
[INFO] [2017-04-07 13:22:59][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 1   Success
[INFO] [2017-04-07 13:22:59][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 2   Success
[INFO] [2017-04-07 13:22:59][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Error
[INFO] [2017-04-07 13:22:59][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 13:23:20][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 13:32:09][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 13:32:30][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 14:46:25][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 14:46:25][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 14:46:25][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 14:46:25][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 14:46:28][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 14:46:28][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 14:46:28][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 14:46:28][com.bacon.client.common.service.ClientService]return {"folder":true} to request
[INFO] [2017-04-07 14:46:28][com.bacon.client.api.app.App]{"folder":true}
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 14:46:28][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 14:46:28][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 14:46:28][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 14:46:28][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 14:46:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 14:46:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 14:46:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 14:46:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 14:46:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 14:46:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 14:46:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 14:46:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 14:46:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 14:46:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 14:46:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 14:46:30][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 14:46:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 14:46:30][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 14:46:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 14:46:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 14:46:30][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 14:46:30][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 14:46:33][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 14:46:34][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test2.txt   upload completely
[INFO] [2017-04-07 14:46:34][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 0   上传成功
[INFO] [2017-04-07 14:46:34][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test3.txt   upload completely
[INFO] [2017-04-07 14:46:34][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 1   上传成功
[INFO] [2017-04-07 14:46:34][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 2   上传成功
[INFO] [2017-04-07 14:46:34][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test2.txt   Success
[INFO] [2017-04-07 14:46:34][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test3.txt   Success
[INFO] [2017-04-07 14:46:34][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test.txt   Success
[INFO] [2017-04-07 14:46:34][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 14:46:47][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 14:46:55][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 14:56:47][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 14:57:08][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:07:08][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 15:07:29][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:17:29][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 15:17:50][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:23:00][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 15:23:00][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 15:23:00][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 15:23:00][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 15:23:17][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[ERROR] [2017-04-07 15:23:18][org.apache.thrift.server.TSimpleServer]Error occurred during processing of message.
java.lang.NullPointerException
	at com.bacon.client.api.service.ClientServiceImpl.receive(ClientServiceImpl.java:108)
	at com.bacon.client.common.service.ClientService$Processor$receive.getResult(ClientService.java:170)
	at com.bacon.client.common.service.ClientService$Processor$receive.getResult(ClientService.java:154)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.thrift.server.TSimpleServer.serve(TSimpleServer.java:80)
	at com.bacon.client.api.thrift.RunningServer.run(RunningServer.java:38)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[INFO] [2017-04-07 15:23:21][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:25:27][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 15:25:27][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 15:25:27][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 15:25:27][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 15:25:30][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 15:25:33][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 15:25:33][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 15:25:33][com.bacon.client.common.service.ClientService]return {"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt","G:\\大三下\\Message Systems\\文档\\test\\test.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"totalSize":298840931} to request
[INFO] [2017-04-07 15:25:33][com.bacon.client.api.app.App]{"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt","G:\\大三下\\Message Systems\\文档\\test\\test.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"totalSize":298840931}
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:25:33][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 15:25:33][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:25:33][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:25:33][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:25:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:25:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:25:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:25:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:25:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:25:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:25:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:25:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:25:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:25:33][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:25:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:25:33][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:25:33][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:25:33][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:25:33][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:25:33][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:25:33][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:25:33][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:25:37][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test3.txt   upload completely
[INFO] [2017-04-07 15:25:37][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test2.txt   upload completely
[INFO] [2017-04-07 15:25:37][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 0   上传成功
[INFO] [2017-04-07 15:25:37][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 1   上传成功
[INFO] [2017-04-07 15:25:37][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 15:25:37][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 2   上传成功
[INFO] [2017-04-07 15:25:37][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test2.txt   Success
[INFO] [2017-04-07 15:25:37][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test3.txt   Success
[INFO] [2017-04-07 15:25:37][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test.txt   Success
[INFO] [2017-04-07 15:25:37][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 15:25:49][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:25:58][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 15:30:56][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 15:30:56][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 15:30:56][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 15:30:56][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 15:30:59][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 15:31:01][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 15:31:01][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:31:01][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 15:31:01][com.bacon.client.common.service.ClientService]return {"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test.txt","G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"totalSize":298840931} to request
[INFO] [2017-04-07 15:31:01][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:31:01][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:31:01][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:31:01][com.bacon.client.api.app.App]{"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test.txt","G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"totalSize":298840931}
[INFO] [2017-04-07 15:31:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:31:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:31:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:31:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:31:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:31:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:31:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:31:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:31:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:31:02][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:31:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:31:02][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:31:02][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:31:02][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:31:02][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:31:02][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:31:02][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:31:02][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:31:06][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test3.txt   upload completely
[INFO] [2017-04-07 15:31:06][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test2.txt   upload completely
[INFO] [2017-04-07 15:31:06][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 0   上传成功
[INFO] [2017-04-07 15:31:06][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 1   上传成功
[INFO] [2017-04-07 15:31:06][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 15:31:06][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 2   上传成功
[INFO] [2017-04-07 15:31:06][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test2.txt   Success
[INFO] [2017-04-07 15:31:06][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test3.txt   Success
[INFO] [2017-04-07 15:31:06][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test.txt   Success
[INFO] [2017-04-07 15:31:06][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 15:31:18][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:31:27][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 15:32:51][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 15:32:52][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 15:32:52][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 15:32:52][com.bacon.client.common.service.ClientService]return {"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","totalSize":99618856} to request
[INFO] [2017-04-07 15:32:52][com.bacon.client.api.app.App]{"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","totalSize":99618856}
[INFO] [2017-04-07 15:32:52][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:32:52][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:32:52][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 15:32:52][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:32:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:32:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:32:52][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:32:52][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-4
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:32:52][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:32:52][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:32:55][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 15:32:55][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 15:32:55][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 15:33:16][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 15:41:18][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 15:41:39][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:43:14][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 15:43:14][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 15:43:14][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 15:43:14][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 15:43:20][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 15:43:21][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 15:43:21][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 15:43:21][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:43:21][com.bacon.client.common.service.ClientService]return {"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","totalSize":99618856} to request
[INFO] [2017-04-07 15:43:21][com.bacon.client.api.app.App]{"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","totalSize":99618856}
[INFO] [2017-04-07 15:43:21][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:43:21][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 15:43:21][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:43:21][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 15:43:22][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:43:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:43:23][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:43:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:43:23][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:43:23][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:43:26][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 15:43:26][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 15:43:26][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 15:43:36][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:43:47][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 15:48:24][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 15:48:24][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 15:48:24][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 15:48:24][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 15:48:26][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 15:48:27][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 15:48:27][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 15:48:27][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:48:27][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:48:27][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 15:48:27][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:48:27][com.bacon.client.common.service.ClientService]return {"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","totalSize":99618856} to request
[INFO] [2017-04-07 15:48:27][com.bacon.client.api.app.App]{"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","totalSize":99618856}
[INFO] [2017-04-07 15:48:28][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 15:48:28][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:48:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:48:29][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:48:29][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:48:29][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:48:29][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:48:32][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 15:48:32][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 15:48:32][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 15:48:46][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:48:53][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 15:51:02][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 15:51:02][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 15:51:02][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 15:51:02][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 15:51:04][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 15:51:05][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 15:51:05][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 15:51:05][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 15:51:05][com.bacon.client.common.service.ClientService]return {"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","totalSize":99618856} to request
[INFO] [2017-04-07 15:51:05][com.bacon.client.api.app.App]{"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","totalSize":99618856}
[INFO] [2017-04-07 15:51:05][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:51:05][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 15:51:05][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 15:51:05][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 15:51:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:51:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:51:06][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 15:51:06][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 15:51:06][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 15:51:06][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 15:51:10][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 15:51:10][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 15:51:10][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 15:51:23][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 15:51:31][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 16:01:23][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 16:01:44][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 16:04:39][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 16:04:39][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 16:04:39][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 16:04:39][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 16:04:42][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 16:04:43][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 16:04:43][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 16:04:43][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:04:43][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:04:43][com.bacon.client.common.service.ClientService]return {"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856} to request
[INFO] [2017-04-07 16:04:43][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 16:04:43][com.bacon.client.api.app.App]{"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856}
[INFO] [2017-04-07 16:04:43][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:04:43][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:04:43][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:04:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:04:44][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:04:44][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:04:44][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:04:44][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:04:47][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 16:04:47][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 16:04:47][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 16:05:00][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 16:05:08][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 16:07:47][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 16:07:47][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 16:07:47][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 16:07:47][com.bacon.client.common.service.ClientService]return {"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856} to request
[INFO] [2017-04-07 16:07:47][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:07:47][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:07:47][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 16:07:47][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:07:47][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:07:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:07:47][com.bacon.client.api.app.App]{"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856}
[INFO] [2017-04-07 16:07:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:07:47][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:07:47][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:07:47][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:07:47][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:07:51][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 16:07:51][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 16:07:51][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 16:08:06][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 16:08:09][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 16:08:09][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 16:08:09][com.bacon.client.common.service.ClientService]return {"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test.txt","G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"schema":"{\"fields\":[{\"name\":\"originstr\",\"type\":\"string\"}],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":298840931} to request
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:08:09][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 16:08:09][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:08:09][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:08:09][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[{"name":"originstr","type":"string"}],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:08:09][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:08:09][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[{"name":"originstr","type":"string"}],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:08:09][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[{"name":"originstr","type":"string"}],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:08:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:08:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:08:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:08:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:08:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:08:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:08:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:08:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:08:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:08:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:08:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-4
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:08:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:08:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:08:09][com.bacon.client.api.app.App]{"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test.txt","G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"schema":"{\"fields\":[{\"name\":\"originstr\",\"type\":\"string\"}],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":298840931}
[INFO] [2017-04-07 16:08:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:08:09][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:08:09][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-5
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:08:09][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:08:09][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:08:12][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 16:08:12][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test2.txt   upload completely
[INFO] [2017-04-07 16:08:12][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 0   上传成功
[INFO] [2017-04-07 16:08:12][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 16:08:12][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test3.txt   upload completely
[INFO] [2017-04-07 16:08:12][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 1   上传成功
[INFO] [2017-04-07 16:08:12][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 2   上传成功
[INFO] [2017-04-07 16:08:12][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test2.txt   Success
[INFO] [2017-04-07 16:08:12][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test3.txt   Success
[INFO] [2017-04-07 16:08:12][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test.txt   Success
[INFO] [2017-04-07 16:08:12][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 16:08:33][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 16:09:07][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 16:09:08][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 16:09:08][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 16:09:08][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:09:08][com.bacon.client.common.service.ClientService]return {"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856} to request
[INFO] [2017-04-07 16:09:08][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:08][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 16:09:08][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:08][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:09:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:08][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:08][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-6
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:08][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:09:08][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:09:08][com.bacon.client.api.app.App]{"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856}
[INFO] [2017-04-07 16:09:10][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 16:09:12][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 16:09:12][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 16:09:12][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 16:09:12][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:09:12][com.bacon.client.common.service.ClientService]return {"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test.txt","G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"schema":"{\"fields\":[{\"name\":\"originstr\",\"type\":\"string\"}],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":298840931} to request
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 16:09:12][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:12][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[{"name":"originstr","type":"string"}],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:09:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 16:09:12][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:12][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[{"name":"originstr","type":"string"}],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:09:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-8
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:09:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:09:12][com.bacon.client.api.app.App]{"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test.txt","G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"schema":"{\"fields\":[{\"name\":\"originstr\",\"type\":\"string\"}],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":298840931}
[INFO] [2017-04-07 16:09:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-7
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:12][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:09:12][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 16:09:12][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:12][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[{"name":"originstr","type":"string"}],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:09:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:12][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:12][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-9
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:13][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:09:13][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:09:12][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 16:09:15][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 16:09:15][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test2.txt   upload completely
[INFO] [2017-04-07 16:09:15][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 0   上传成功
[INFO] [2017-04-07 16:09:15][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test3.txt   upload completely
[INFO] [2017-04-07 16:09:15][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 1   上传成功
[INFO] [2017-04-07 16:09:15][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 2   上传成功
[INFO] [2017-04-07 16:09:15][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test2.txt   Success
[INFO] [2017-04-07 16:09:15][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test3.txt   Success
[INFO] [2017-04-07 16:09:15][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test.txt   Success
[INFO] [2017-04-07 16:09:15][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 16:09:31][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 16:09:32][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 16:09:32][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:09:32][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:32][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 16:09:32][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:09:32][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 16:09:32][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:09:32][com.bacon.client.common.service.ClientService]return {"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856} to request
[INFO] [2017-04-07 16:09:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:32][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:09:32][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-10
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:09:32][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:09:32][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:09:32][com.bacon.client.api.app.App]{"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856}
[INFO] [2017-04-07 16:09:33][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 16:09:35][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 16:09:35][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 16:09:35][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 16:09:36][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 16:09:56][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 16:15:13][com.bacon.client.common.util.AsyncTaskUtils]Threadpool Running!
[INFO] [2017-04-07 16:15:13][com.bacon.client.api.thrift.ServerStart]Start Server!
[INFO] [2017-04-07 16:15:13][com.bacon.client.api.thrift.RunningServer]
Running Server in : 9922
[INFO] [2017-04-07 16:15:13][com.bacon.client.common.http.HttpGetAliveTask]send get alive request: http://125.216.243.41:8888/getalive
[INFO] [2017-04-07 16:15:22][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 16:15:23][com.bacon.client.common.service.ClientService]
Turn to File Upload task executor.....
[INFO] [2017-04-07 16:15:23][com.bacon.client.common.service.ClientService]
Executing file future task.....
[INFO] [2017-04-07 16:15:23][com.bacon.client.common.service.ClientService]return {"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856} to request
[INFO] [2017-04-07 16:15:23][com.bacon.client.api.app.App]{"folder":false,"md5":"d5f6f09a1660e75524d28ee78848acc0","schema":"{\"fields\":[],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":99618856}
[INFO] [2017-04-07 16:15:23][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:15:23][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:15:23][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 16:15:23][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"123456","isAllString":false,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test\\test.txt","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:15:23][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:15:23][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:15:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:15:24][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:15:24][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-1
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:15:24][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:15:24][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:15:27][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 16:15:27][com.bacon.client.common.service.ClientService]TaskId: 2    Info: Success
[INFO] [2017-04-07 16:15:27][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 16:15:35][com.bacon.client.common.http.HttpGetAliveTask]get alive response: null
[INFO] [2017-04-07 16:15:35][com.bacon.client.api.app.App]aim server ip : 127.0.0.1
aim server port : 9922
[INFO] [2017-04-07 16:15:37][com.bacon.client.common.service.ClientService]
Turn to File list upload task executor.....
[INFO] [2017-04-07 16:15:37][com.bacon.client.common.service.ClientService]
Executing file list future task.....
[INFO] [2017-04-07 16:15:37][com.bacon.client.common.service.ClientService]return {"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test.txt","G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"schema":"{\"fields\":[{\"name\":\"originstr\",\"type\":\"string\"}],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":298840931} to request
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileListUploadCallableTask]所有文件任务提交完成，线程池正在运行...
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileUploadCallableTask]Here is file upload task...
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test.txt
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test2.txt
[INFO] [2017-04-07 16:15:37][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileUploadCallableTask]The parameter: {"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:15:37][com.bacon.client.core.callable.FileUploadCallableTask]
filename: test3.txt
[INFO] [2017-04-07 16:15:37][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:15:37][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[{"name":"originstr","type":"string"}],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:15:37][com.b3434.Factory.ProcessorFactory]parameter={"aESPriKey":"1234567821676878","isAllString":true,"isEncrypted":false,"isPart":false,"isRegexed":false,"isSplited":false,"isWholeDb":false,"isWholeTable":false,"path":"G:\\大三下\\Message Systems\\文档\\test","securityLevel":2,"topic":"test"}
[INFO] [2017-04-07 16:15:37][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[{"name":"originstr","type":"string"}],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:15:37][com.b3434.Factory.ProcessorFactory]OfflineSchemaStr={"fields":[{"name":"originstr","type":"string"}],"name":"test","namespace":"com.taotie.offline","type":"record"}
[INFO] [2017-04-07 16:15:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:15:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:15:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:15:37][com.bacon.client.api.app.App]{"fileList":["G:\\大三下\\Message Systems\\文档\\test\\test.txt","G:\\大三下\\Message Systems\\文档\\test\\test2.txt","G:\\大三下\\Message Systems\\文档\\test\\test3.txt"],"fileSize":[99618856,99605030,99617045],"folder":true,"md5List":["d5f6f09a1660e75524d28ee78848acc0","17218b6c45294d1166648da1250e23ab","a8416417452ff4862998b0eebf0525f9"],"schema":"{\"fields\":[{\"name\":\"originstr\",\"type\":\"string\"}],\"name\":\"test\",\"namespace\":\"com.taotie.offline\",\"type\":\"record\"}","totalSize":298840931}
[INFO] [2017-04-07 16:15:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:15:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:15:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-2
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:15:37][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:15:37][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:15:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:15:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:15:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-4
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:15:37][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:15:37][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:15:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:15:37][io.confluent.kafka.serializers.KafkaAvroSerializerConfig]KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://192.168.10.150:8081]
	max.schemas.per.subject = 1000

[INFO] [2017-04-07 16:15:37][org.apache.kafka.clients.producer.ProducerConfig]ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [192.168.10.150:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-3
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = 1
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 16384
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	linger.ms = 0

[INFO] [2017-04-07 16:15:37][org.apache.kafka.common.utils.AppInfoParser]Kafka version : 0.10.0.0-cp1
[INFO] [2017-04-07 16:15:37][org.apache.kafka.common.utils.AppInfoParser]Kafka commitId : 7c67d65755e5b1ab
[INFO] [2017-04-07 16:15:41][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test3.txt   upload completely
[INFO] [2017-04-07 16:15:41][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test2.txt   upload completely
[INFO] [2017-04-07 16:15:41][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 0   上传成功
[INFO] [2017-04-07 16:15:41][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 1   上传成功
[INFO] [2017-04-07 16:15:41][com.bacon.client.core.callable.FileUploadCallableTask]Task 2   test.txt   upload completely
[INFO] [2017-04-07 16:15:41][com.bacon.client.core.callable.FileListUploadCallableTask]2   file 2   上传成功
[INFO] [2017-04-07 16:15:41][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test2.txt   Success
[INFO] [2017-04-07 16:15:41][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test3.txt   Success
[INFO] [2017-04-07 16:15:41][com.bacon.client.common.service.ClientService]TaskId: 2   G:\大三下\Message Systems\文档\test\test.txt   Success
[INFO] [2017-04-07 16:15:41][com.bacon.client.api.http.HttpReturnBackTask]send task complete url: http://125.216.243.41:8888/taskcomplete
[INFO] [2017-04-07 16:15:48][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
[INFO] [2017-04-07 16:16:02][com.bacon.client.api.http.HttpReturnBackTask]after send task complete meg, response: null
